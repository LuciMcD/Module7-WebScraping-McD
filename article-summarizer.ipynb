{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Mining and Applied NLP (44-620)\n",
    "\n",
    "## Final Project: Article Summarizer\n",
    "\n",
    "### Student Name: Luci McDaniel\n",
    "### GitHub: https://github.com/LuciMcD/Module7-WebScraping-McD.git \n",
    "\n",
    "Perform the tasks described in the Markdown cells below.  When you have completed the assignment make sure your code cells have all been run (and have output beneath them) and ensure you have committed and pushed ALL of your changes to your assignment repository.\n",
    "\n",
    "You should bring in code from previous assignments to help you answer the questions below.\n",
    "\n",
    "Every question that requires you to write code will have a code cell underneath it; you may either write your entire solution in that cell or write it in a python file (`.py`), then import and run the appropriate code to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "1. Find on the internet an article or blog post about a topic that interests you and you are able to get the text for using the technologies we have applied in the course.  Get the html for the article and store it in a file (which you must submit with your project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = requests.get('https://poets.org/poem/my-people')\n",
    "with open('poem.pkl', 'wb') as f:\n",
    "    pickle.dump(poem.text, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "2. Read in your article's html source from the file you created in question 1 and do sentiment analysis on the article/post's text (use `.get_text()`).  Print the polarity score with an appropriate label.  Additionally print the number of sentences in the original article (with an appropriate label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "For My People\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Add to anthology\n",
      "\n",
      "×\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Margaret Walker\n",
      "\n",
      "\n",
      "1915 – \n",
      "1998\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For my people everywhere singing their slave songs     repeatedly: their dirges and their ditties and their blues       and jubilees, praying their prayers nightly to an     unknown god, bending their knees humbly to an     unseen power;\n",
      "For my people lending their strength to the years, to the      gone years and the now years and the maybe years,    washing ironing cooking scrubbing sewing mending    hoeing plowing digging planting pruning patching     dragging along never gaining never reaping never    knowing and never understanding;\n",
      "For my playmates in the clay and dust and sand of Alabama     backyards playing baptizing and preaching and doctor    and jail and soldier and school and mama and cooking    and playhouse and concert and store and hair and Miss     Choomby and company;\n",
      "For the cramped bewildered years we went to school to learn      to know the reasons why and the answers to and the    people who and the places where and the days when, in    memory of the bitter hours when we discovered we    were black and poor and small and different and nobody    cared and nobody wondered and nobody understood;\n",
      "For the boys and girls who grew in spite of these things to    be man and woman, to laugh and dance and sing and    play and drink their wine and religion and success, to    marry their playmates and bear children and then die     of consumption and anemia and lynching;\n",
      "For my people thronging 47th Street in Chicago and Lenox    Avenue in New York and Rampart Street in New    Orleans, lost disinherited dispossessed and happy    people filling the cabarets and taverns and other    people’s pockets needing bread and shoes and milk and     land and money and something—something all our own;\n",
      "For my people walking blindly spreading joy, losing time     being lazy, sleeping when hungry, shouting when     burdened, drinking when hopeless, tied, and shackled     and tangled among ourselves by the unseen creatures     who tower over us omnisciently and laugh;\n",
      "For my people blundering and groping and floundering in     the dark of churches and schools and clubs and      societies, associations and councils and committees and       conventions, distressed and disturbed and deceived and     devoured by money-hungry glory-craving leeches,     preyed on by facile force of state and fad and novelty, by     false prophet and holy believer;\n",
      "For my people standing staring trying to fashion a better way     from confusion, from hypocrisy and misunderstanding,    trying to fashion a world that will hold all the people,    all the faces, all the adams and eves and their countless     generations;\n",
      "Let a new earth rise. Let another world be born. Let a    bloody peace be written in the sky. Let a second    generation full of courage issue forth; let a people    loving freedom come to growth. Let a beauty full of    healing and a strength of final clenching be the pulsing    in our spirits and our blood. Let the martial songs    be written, let the dirges disappear. Let a race of men now      rise and take control.\n",
      "\n",
      "From This Is My Century: New and Collected Poems (University of Georgia Press, 1989). Copyright © 1989 by Margaret Walker. Used with permission of the University of Georgia Press.\n",
      "\n",
      "\n",
      "\n",
      "The polarity score of FOR MY PEOPLE is  0.05\n",
      "The number of lines in the poem: 16\n"
     ]
    }
   ],
   "source": [
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "poem_html = poem.text\n",
    "\n",
    "with open('poem.pkl', 'rb') as f:\n",
    "    poem_html = pickle.load(f)\n",
    "\n",
    "parser = 'html.parser'\n",
    "soup = BeautifulSoup(poem_html, parser)\n",
    "extract_poem = soup.find('article')\n",
    "formypeople = extract_poem.get_text()\n",
    "print(formypeople)\n",
    "#poem_lines = soup.find_all('p')\n",
    "#print(poem_lines[1].get_text())\n",
    "\n",
    "#printing the polarity score \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "doc = nlp(formypeople)\n",
    "\n",
    "polarity = doc._.blob.polarity\n",
    "print(\"The polarity score of FOR MY PEOPLE is \", round(polarity, 2))\n",
    "\n",
    "#printing the number of sentences\n",
    "poem_lines = soup.find_all('p')\n",
    "total_lines = len(poem_lines)\n",
    "print(\"The number of lines in the poem:\",total_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "3. Load the article text into a trained `spaCy` pipeline, and determine the 5 most frequent tokens (converted to lower case).  Print the common tokens with an appropriate label.  Additionally, print the tokens their frequencies (with appropriate labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "4. Load the article text into a trained `spaCy` pipeline, and determine the 5 most frequent lemmas (converted to lower case).  Print the common lemmas with an appropriate label.  Additionally, print the lemmas with their frequencies (with appropriate labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "5. Make a list containing the scores (using tokens) of every sentence in the article, and plot a histogram with appropriate titles and axis labels of the scores. From your histogram, what seems to be the most common range of scores (put the answer in a comment after your code)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6:\n",
    "6. Make a list containing the scores (using lemmas) of every sentence in the article, and plot a histogram with appropriate titles and axis labels of the scores.  From your histogram, what seems to be the most common range of scores (put the answer in a comment after your code)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7:\n",
    "7. Using the histograms from questions 5 and 6, decide a \"cutoff\" score for tokens and lemmas such that fewer than half the sentences would have a score greater than the cutoff score.  Record the scores in this Markdown cell\n",
    "\n",
    "* Cutoff Score (tokens): \n",
    "* Cutoff Score (lemmas):\n",
    "\n",
    "Feel free to change these scores as you generate your summaries.  Ideally, we're shooting for at least 6 sentences for our summary, but don't want more than 10 (these numbers are rough estimates; they depend on the length of your article)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8:\n",
    "8. Create a summary of the article by going through every sentence in the article and adding it to an (initially) empty list if its score (based on tokens) is greater than the cutoff score you identified in question 8.  If your loop variable is named `sent`, you may find it easier to add `sent.text.strip()` to your list of sentences.  Print the summary (I would cleanly generate the summary text by `join`ing the strings in your list together with a space (`' '.join(sentence_list)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9:\n",
    "9. Print the polarity score of your summary you generated with the token scores (with an appropriate label). Additionally, print the number of sentences in the summarized article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10:\n",
    "10. Create a summary of the article by going through every sentence in the article and adding it to an (initially) empty list if its score (based on lemmas) is greater than the cutoff score you identified in question 8.  If your loop variable is named `sent`, you may find it easier to add `sent.text.strip()` to your list of sentences.  Print the summary (I would cleanly generate the summary text by `join`ing the strings in your list together with a space (`' '.join(sentence_list)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11:\n",
    "11. Print the polarity score of your summary you generated with the lemma scores (with an appropriate label). Additionally, print the number of sentences in the summarized article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12:\n",
    "12.  Compare your polarity scores of your summaries to the polarity scores of the initial article.  Is there a difference?  Why do you think that may or may not be?.  Answer in this Markdown cell.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13:\n",
    "13. Based on your reading of the original article, which summary do you think is better (if there's a difference).  Why do you think this might be?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
